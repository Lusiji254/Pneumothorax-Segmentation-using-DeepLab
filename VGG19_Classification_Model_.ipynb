{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lusiji254/Pneumothorax-Segmentation-using-DeepLab/blob/main/VGG19_Classification_Model_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "metadata": {
        "id": "gG7xS1gACymQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UdSc4QafhLF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(size, num_classes):\n",
        "    inputs = Input((size, size, 3))\n",
        "    backbone = VGG19(input_tensor=inputs, include_top=False, weights=\"imagenet\")\n",
        "    backbone.trainable = False\n",
        "    x = backbone.output\n",
        "    x = GlobalAveragePooling2D()(x.layers[-3].output)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(1024, activation=\"relu\")(x)\n",
        "    x = Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "kA3VoM_sDM_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path, size):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (size, size))\n",
        "    image = image / 255.0\n",
        "    image = image.astype(np.float32)\n",
        "    return image\n",
        "\n",
        "def parse_data(x, y):\n",
        "    x = x.decode()\n",
        "\n",
        "    num_class = 2\n",
        "    size = 224\n",
        "\n",
        "    image = read_image(x, size)\n",
        "    label = [0] * num_class\n",
        "    label[y] = 1\n",
        "    label = np.array(label)\n",
        "    label = label.astype(np.int32)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    x, y = tf.numpy_function(parse_data, [x, y], [tf.float32, tf.int32])\n",
        "    x.set_shape((224, 224, 3))\n",
        "    y.set_shape((2))\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "WOOOKg-CI0l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "UrtfA6AQjZqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    path = \"/content/gdrive/MyDrive/Pneumothorax\"\n",
        "    train_path = os.path.join(path, \"downsampled_train_images/*\")\n",
        "    test_path = os.path.join(path, \"test_images/*\")\n",
        "    labels_path = os.path.join(path, \"downsampled_train.csv\")\n",
        "\n",
        "    labels_df = pd.read_csv(labels_path)\n",
        "    Pneumothorax = labels_df[\"has_pneumo\"].unique()\n",
        "    print(\"Number of Classes: \", len(Pneumothorax))\n",
        "\n",
        "    ids = glob(train_path)\n",
        "    labels = []\n",
        "\n",
        "    for image_name in ids:\n",
        "        image_name = image_name.split(\"/\")[-1]\n",
        "        image_with_class = list(labels_df[labels_df.new_filename == image_name][\"has_pneumo\"])[0]\n",
        "        labels.append(image_with_class)\n",
        "\n",
        "    train_x, valid_x = train_test_split(ids, test_size=0.2, random_state=42)\n",
        "    train_y, valid_y = train_test_split(labels, test_size=0.2, random_state=42)\n",
        " \n",
        "\n",
        "\n",
        "   ## Parameters\n",
        "    size = 256\n",
        "    num_classes = 2\n",
        "    lr = 1e-3\n",
        "    batch = 16\n",
        "    epochs = 100\n",
        "    model_path = os.path.join(\"/content/gdrive/MyDrive/Pneumothorax/pneumo-classify\", \"classification_model_tbrl.h5\")\n",
        "\n",
        "    ## Model\n",
        "    model = build_model(size, num_classes)\n",
        "    adam = tf.keras.optimizers.Adam(lr=0.001)\n",
        "    precision = tf.keras.metrics.Precision(name='precision')\n",
        "    recall = tf.keras.metrics.Recall(name='recall')\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr), metrics=[\"accuracy\",f1, recall, precision])\n",
        "\n",
        "\n",
        "    ## Dataset\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n",
        "\n",
        "     ## Training\n",
        "    %rm -rf ./log\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir='/content/gdrive/MyDrive/Pneumothorax/Tensorboard'\n",
        "    %reload_ext tensorboard\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='/content/gdrive/MyDrive/Pneumothorax/Tensorboard')\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
        "        tensorboard_callback\n",
        "    ]\n",
        "    train_steps = (len(train_x)//batch) + 1\n",
        "    valid_steps = (len(valid_x)//batch) + 1\n",
        "    model.fit(train_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VUZoIcZuhjNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt \n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "\n",
        "H = 256\n",
        "W = 256\n",
        "\n",
        "\n",
        "def read_image(path, size):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (size, size))\n",
        "    image = image / 255.0\n",
        "    image = image.astype(np.float32)\n",
        "    return image\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path = \"/content/gdrive/MyDrive/Pneumothorax\"\n",
        "    test_path = os.path.join(path, \"test_images/*\")\n",
        "    labels_path = os.path.join(path, \"stage_1_test_images.csv\")\n",
        "\n",
        "    labels_df = pd.read_csv(labels_path)\n",
        "    Pneumothorax = labels_df[\"has_pneumo\"].unique()\n",
        "    print(\"Number of Classes: \", len(Pneumothorax))\n",
        "   \n",
        "    ids = glob(test_path)\n",
        "    labels = []\n",
        "     \n",
        "    for image_name in ids:\n",
        "        image_name = image_name.split(\"/\")[-1]\n",
        "        image_with_class = list(labels_df[labels_df.new_filename == image_name][\"has_pneumo\"])[0]\n",
        "        labels.append(image_with_class)\n",
        "\n",
        "    test_x = ids[:200]\n",
        "    test_y = labels[:200]  \n",
        "\n",
        "    ## Model\n",
        "    with CustomObjectScope({'f1':f1}):\n",
        "        model_path = os.path.join(\"/content/gdrive/MyDrive/Pneumothorax/pneumo-classify\", \"chexnet_model.h5\")\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    for i, path in tqdm(enumerate(test_x[:10])):\n",
        "          image = read_image(path, 256)\n",
        "          image = np.expand_dims(image, axis=0)\n",
        "          print(image.shape)\n",
        "          y_pred = model.evaluate(image)[0]\n",
        "          y_pred = np.argmax(y_pred)\n",
        "          \n",
        "          ori_pneumo = [test_y[i]]\n",
        "          ori_image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "\n",
        "          f, (ax1) = plt.subplots(1, 1, figsize=(10,5))\n",
        "                  \n",
        "          ax1.set_title(f'IMAGE. The initial class was: {ori_pneumo}, the prediction is: {y_pred}')\n",
        "          ax1.imshow(image[0])\n"
      ],
      "metadata": {
        "id": "0wsWWt47VbAa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}